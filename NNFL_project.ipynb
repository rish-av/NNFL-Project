{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 647  499  464  371  291  319  365  322  296  305  277  219  219  222\n",
      "  201  162  157  183  204  194  198  216  249  284  294  322  338  342\n",
      "  336  342  362  365  348  341  324  316  293  274  251  244  263  248\n",
      "  236  254  255  240  223  203  202  191  185  200  203  181  168  174\n",
      "  185  187  165  151  144  140  149  169  192  227  287  376  493  633\n",
      "  763  913 1149 1442 1759 2102 2425 2689 2895 3058 3196 3252 3195 3297\n",
      " 3542 3550 3537 3545 3514 3477 3468 3433 3408 3420 3416 3335 3256 3226\n",
      " 3205 3210 3221 3238 3250]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dataset = io.loadmat('PaviaU.mat')['paviaU']\n",
    "gt_labels = io.loadmat('PaviaU_gt.mat')['paviaU_gt']\n",
    "print(dataset[0][0])\n",
    "print(gt_labels[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {x:[] for x in range(1,10)}\n",
    "(x,y,z) = dataset.shape\n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        l = gt_labels[i][j]\n",
    "        if l!=0:\n",
    "            a[l].append(np.array(dataset[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6631\n",
      "18649\n",
      "2099\n",
      "3064\n",
      "1345\n",
      "5029\n",
      "1330\n",
      "3682\n",
      "947\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(len(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "for i in range(1,10):\n",
    "    for j in range(len(a[i])):\n",
    "        X.append(a[i][j])\n",
    "        y.append(i)\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.utils import to_categorical\n",
    "X = normalize(X,axis=1,return_norm=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_test = X_test.reshape(len(X_test),103,1,1)\n",
    "X_train = X_train.reshape(len(X_train),103,1,1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = y_train[:,1:]\n",
    "y_test = y_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , Flatten, MaxPooling2D\n",
    "from keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 93, 1, 20)         240       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 620)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               62100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 909       \n",
      "=================================================================\n",
      "Total params: 63,249\n",
      "Trainable params: 63,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import RandomUniform\n",
    "initializer = RandomUniform(minval=-0.05, maxval=0.05)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size=(11,1), activation='tanh', input_shape=(103,1,1),kernel_initializer=initializer,bias_initializer='zeros'))\n",
    "model.add(MaxPooling2D(pool_size = (3,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='tanh',kernel_initializer=initializer))\n",
    "model.add(Dense(9,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28659 samples, validate on 14117 samples\n",
      "Epoch 1/20\n",
      "28659/28659 [==============================] - 2s 72us/step - loss: 1.2442 - acc: 0.5602 - val_loss: 0.8296 - val_acc: 0.6606\n",
      "Epoch 2/20\n",
      "28659/28659 [==============================] - 2s 70us/step - loss: 0.7634 - acc: 0.6784 - val_loss: 0.7332 - val_acc: 0.7172\n",
      "Epoch 3/20\n",
      "28659/28659 [==============================] - 2s 70us/step - loss: 0.6984 - acc: 0.7082 - val_loss: 0.6904 - val_acc: 0.7320\n",
      "Epoch 4/20\n",
      "28659/28659 [==============================] - 2s 75us/step - loss: 0.6645 - acc: 0.7280 - val_loss: 0.6615 - val_acc: 0.7342\n",
      "Epoch 5/20\n",
      "28659/28659 [==============================] - 2s 71us/step - loss: 0.6421 - acc: 0.7381 - val_loss: 0.6404 - val_acc: 0.7301\n",
      "Epoch 6/20\n",
      "28659/28659 [==============================] - 2s 78us/step - loss: 0.6204 - acc: 0.7505 - val_loss: 0.6193 - val_acc: 0.7548\n",
      "Epoch 7/20\n",
      "28659/28659 [==============================] - 2s 69us/step - loss: 0.6000 - acc: 0.7633 - val_loss: 0.6041 - val_acc: 0.7707\n",
      "Epoch 8/20\n",
      "28659/28659 [==============================] - 2s 70us/step - loss: 0.5782 - acc: 0.7739 - val_loss: 0.5792 - val_acc: 0.7614\n",
      "Epoch 9/20\n",
      "28659/28659 [==============================] - 2s 70us/step - loss: 0.5606 - acc: 0.7860 - val_loss: 0.5590 - val_acc: 0.7973\n",
      "Epoch 10/20\n",
      "28659/28659 [==============================] - 2s 73us/step - loss: 0.5404 - acc: 0.7972 - val_loss: 0.5408 - val_acc: 0.7992\n",
      "Epoch 11/20\n",
      "28659/28659 [==============================] - 2s 75us/step - loss: 0.5246 - acc: 0.8070 - val_loss: 0.5202 - val_acc: 0.8147\n",
      "Epoch 12/20\n",
      "28659/28659 [==============================] - 2s 74us/step - loss: 0.5056 - acc: 0.8153 - val_loss: 0.5073 - val_acc: 0.8245\n",
      "Epoch 13/20\n",
      "28659/28659 [==============================] - 2s 75us/step - loss: 0.4918 - acc: 0.8206 - val_loss: 0.4920 - val_acc: 0.8119\n",
      "Epoch 14/20\n",
      "28659/28659 [==============================] - 2s 73us/step - loss: 0.4788 - acc: 0.8270 - val_loss: 0.4864 - val_acc: 0.8158\n",
      "Epoch 15/20\n",
      "28659/28659 [==============================] - 2s 73us/step - loss: 0.4713 - acc: 0.8273 - val_loss: 0.4576 - val_acc: 0.8417\n",
      "Epoch 16/20\n",
      "28659/28659 [==============================] - 2s 75us/step - loss: 0.4538 - acc: 0.8365 - val_loss: 0.4511 - val_acc: 0.8425\n",
      "Epoch 17/20\n",
      "28659/28659 [==============================] - 2s 73us/step - loss: 0.4435 - acc: 0.8389 - val_loss: 0.4423 - val_acc: 0.8405\n",
      "Epoch 18/20\n",
      "28659/28659 [==============================] - 2s 73us/step - loss: 0.4344 - acc: 0.8434 - val_loss: 0.4377 - val_acc: 0.8345\n",
      "Epoch 19/20\n",
      "28659/28659 [==============================] - 2s 73us/step - loss: 0.4241 - acc: 0.8463 - val_loss: 0.4209 - val_acc: 0.8498\n",
      "Epoch 20/20\n",
      "28659/28659 [==============================] - 2s 76us/step - loss: 0.4260 - acc: 0.8435 - val_loss: 0.4207 - val_acc: 0.8501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fead8dcbcc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data = (X_test,y_test),epochs = 20,verbose=1,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
