{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 647  499  464  371  291  319  365  322  296  305  277  219  219  222\n",
      "  201  162  157  183  204  194  198  216  249  284  294  322  338  342\n",
      "  336  342  362  365  348  341  324  316  293  274  251  244  263  248\n",
      "  236  254  255  240  223  203  202  191  185  200  203  181  168  174\n",
      "  185  187  165  151  144  140  149  169  192  227  287  376  493  633\n",
      "  763  913 1149 1442 1759 2102 2425 2689 2895 3058 3196 3252 3195 3297\n",
      " 3542 3550 3537 3545 3514 3477 3468 3433 3408 3420 3416 3335 3256 3226\n",
      " 3205 3210 3221 3238 3250]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dataset = io.loadmat('PaviaU.mat')['paviaU']\n",
    "gt_labels = io.loadmat('PaviaU_gt.mat')['paviaU_gt']\n",
    "print(dataset[0][0])\n",
    "print(gt_labels[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {x:[] for x in range(1,10)}\n",
    "(x,y,z) = dataset.shape\n",
    "for i in range(x):\n",
    "    for j in range(y):\n",
    "        l = gt_labels[i][j]\n",
    "        if l!=0:\n",
    "            a[l].append(np.array(dataset[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6631\n",
      "18649\n",
      "2099\n",
      "3064\n",
      "1345\n",
      "5029\n",
      "1330\n",
      "3682\n",
      "947\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(len(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "for i in range(1,10):\n",
    "    for j in range(len(a[i])):\n",
    "        X.append(a[i][j])\n",
    "        y.append(i)\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.utils import to_categorical\n",
    "X = normalize(X,axis=1,return_norm=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_test = X_test.reshape(len(X_test),103,1,1)\n",
    "X_train = X_train.reshape(len(X_train),103,1,1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = y_train[:,1:]\n",
    "y_test = y_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , Flatten, MaxPooling2D , Dropout\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 93, 1, 20)         240       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 31, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 620)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               62100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 9)                 909       \n",
      "=================================================================\n",
      "Total params: 63,249\n",
      "Trainable params: 63,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import RandomUniform\n",
    "initializer = RandomUniform(minval=-0.05, maxval=0.05)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size=(11,1), activation='tanh', input_shape=(103,1,1),kernel_initializer=initializer,bias_initializer='zeros'))\n",
    "model.add(MaxPooling2D(pool_size = (3,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='tanh',kernel_initializer=initializer))\n",
    "model.add(Dense(9,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28659 samples, validate on 14117 samples\n",
      "Epoch 1/50\n",
      "28659/28659 [==============================] - 5s 184us/step - loss: 0.1978 - acc: 0.9247 - val_loss: 0.2184 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.92576\n",
      "Epoch 2/50\n",
      "28659/28659 [==============================] - 5s 189us/step - loss: 0.1969 - acc: 0.9253 - val_loss: 0.2084 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92576\n",
      "Epoch 3/50\n",
      "28659/28659 [==============================] - 5s 190us/step - loss: 0.1931 - acc: 0.9274 - val_loss: 0.2003 - val_acc: 0.9255\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92576\n",
      "Epoch 4/50\n",
      "28659/28659 [==============================] - 6s 196us/step - loss: 0.1947 - acc: 0.9249 - val_loss: 0.2215 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92576\n",
      "Epoch 5/50\n",
      "28659/28659 [==============================] - 6s 192us/step - loss: 0.1947 - acc: 0.9262 - val_loss: 0.2024 - val_acc: 0.9258\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92576\n",
      "Epoch 6/50\n",
      "28659/28659 [==============================] - 6s 197us/step - loss: 0.1931 - acc: 0.9275 - val_loss: 0.2097 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92576\n",
      "Epoch 7/50\n",
      "28659/28659 [==============================] - 6s 192us/step - loss: 0.1907 - acc: 0.9264 - val_loss: 0.1954 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.92576 to 0.92590, saving model to weights-improvement-07-0.93.hdf5\n",
      "Epoch 8/50\n",
      "28659/28659 [==============================] - 6s 200us/step - loss: 0.1891 - acc: 0.9282 - val_loss: 0.2000 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92590 to 0.92711, saving model to weights-improvement-08-0.93.hdf5\n",
      "Epoch 9/50\n",
      "28659/28659 [==============================] - 6s 192us/step - loss: 0.1871 - acc: 0.9285 - val_loss: 0.2018 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92711 to 0.92789, saving model to weights-improvement-09-0.93.hdf5\n",
      "Epoch 10/50\n",
      "28659/28659 [==============================] - 6s 195us/step - loss: 0.1837 - acc: 0.9285 - val_loss: 0.2064 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92789\n",
      "Epoch 11/50\n",
      "28659/28659 [==============================] - 6s 196us/step - loss: 0.1833 - acc: 0.9308 - val_loss: 0.1976 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92789\n",
      "Epoch 12/50\n",
      "28659/28659 [==============================] - 6s 194us/step - loss: 0.1838 - acc: 0.9284 - val_loss: 0.2003 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92789\n",
      "Epoch 13/50\n",
      "28659/28659 [==============================] - 6s 200us/step - loss: 0.1817 - acc: 0.9306 - val_loss: 0.1936 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92789\n",
      "Epoch 14/50\n",
      "28659/28659 [==============================] - 6s 201us/step - loss: 0.1801 - acc: 0.9313 - val_loss: 0.1913 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.92789 to 0.93008, saving model to weights-improvement-14-0.93.hdf5\n",
      "Epoch 15/50\n",
      "28659/28659 [==============================] - 6s 196us/step - loss: 0.1781 - acc: 0.9334 - val_loss: 0.1914 - val_acc: 0.9295\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93008\n",
      "Epoch 16/50\n",
      "28659/28659 [==============================] - 6s 199us/step - loss: 0.1779 - acc: 0.9314 - val_loss: 0.1859 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.93008 to 0.93136, saving model to weights-improvement-16-0.93.hdf5\n",
      "Epoch 17/50\n",
      "28659/28659 [==============================] - 6s 195us/step - loss: 0.1809 - acc: 0.9313 - val_loss: 0.1874 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93136\n",
      "Epoch 18/50\n",
      "28659/28659 [==============================] - 6s 199us/step - loss: 0.1757 - acc: 0.9338 - val_loss: 0.1963 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93136\n",
      "Epoch 19/50\n",
      "28659/28659 [==============================] - 6s 197us/step - loss: 0.1769 - acc: 0.9309 - val_loss: 0.2099 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93136\n",
      "Epoch 20/50\n",
      "28659/28659 [==============================] - 6s 199us/step - loss: 0.1746 - acc: 0.9333 - val_loss: 0.2189 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93136\n",
      "Epoch 21/50\n",
      "28659/28659 [==============================] - 6s 201us/step - loss: 0.1724 - acc: 0.9345 - val_loss: 0.1831 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.93136 to 0.93292, saving model to weights-improvement-21-0.93.hdf5\n",
      "Epoch 22/50\n",
      "28659/28659 [==============================] - 6s 212us/step - loss: 0.1709 - acc: 0.9341 - val_loss: 0.1820 - val_acc: 0.9327\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93292\n",
      "Epoch 23/50\n",
      "28659/28659 [==============================] - 6s 209us/step - loss: 0.1720 - acc: 0.9344 - val_loss: 0.1999 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.93292\n",
      "Epoch 24/50\n",
      "28659/28659 [==============================] - 6s 209us/step - loss: 0.1693 - acc: 0.9350 - val_loss: 0.1817 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93292\n",
      "Epoch 25/50\n",
      "28659/28659 [==============================] - 6s 208us/step - loss: 0.1700 - acc: 0.9349 - val_loss: 0.1890 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93292\n",
      "Epoch 26/50\n",
      "28659/28659 [==============================] - 6s 208us/step - loss: 0.1678 - acc: 0.9363 - val_loss: 0.1875 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.93292\n",
      "Epoch 27/50\n",
      "28659/28659 [==============================] - 6s 209us/step - loss: 0.1669 - acc: 0.9354 - val_loss: 0.1821 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.93292\n",
      "Epoch 28/50\n",
      "28659/28659 [==============================] - 6s 209us/step - loss: 0.1648 - acc: 0.9370 - val_loss: 0.1849 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.93292\n",
      "Epoch 29/50\n",
      "28659/28659 [==============================] - 6s 210us/step - loss: 0.1660 - acc: 0.9367 - val_loss: 0.1825 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.93292\n",
      "Epoch 30/50\n",
      "28659/28659 [==============================] - 6s 210us/step - loss: 0.1617 - acc: 0.9367 - val_loss: 0.1814 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93292\n",
      "Epoch 31/50\n",
      "28659/28659 [==============================] - 6s 212us/step - loss: 0.1610 - acc: 0.9375 - val_loss: 0.1817 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.93292 to 0.93292, saving model to weights-improvement-31-0.93.hdf5\n",
      "Epoch 32/50\n",
      "28659/28659 [==============================] - 6s 210us/step - loss: 0.1634 - acc: 0.9376 - val_loss: 0.1818 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93292\n",
      "Epoch 33/50\n",
      "28659/28659 [==============================] - 6s 210us/step - loss: 0.1617 - acc: 0.9373 - val_loss: 0.1944 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.93292\n",
      "Epoch 34/50\n",
      "28659/28659 [==============================] - 6s 210us/step - loss: 0.1568 - acc: 0.9394 - val_loss: 0.1878 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.93292\n",
      "Epoch 35/50\n",
      "28659/28659 [==============================] - 6s 210us/step - loss: 0.1601 - acc: 0.9384 - val_loss: 0.2189 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.93292\n",
      "Epoch 36/50\n",
      "28659/28659 [==============================] - 6s 210us/step - loss: 0.1564 - acc: 0.9390 - val_loss: 0.1760 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.93292 to 0.93334, saving model to weights-improvement-36-0.93.hdf5\n",
      "Epoch 37/50\n",
      "28659/28659 [==============================] - 6s 212us/step - loss: 0.1577 - acc: 0.9393 - val_loss: 0.1923 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.93334\n",
      "Epoch 38/50\n",
      "28659/28659 [==============================] - 6s 213us/step - loss: 0.1561 - acc: 0.9390 - val_loss: 0.1999 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.93334\n",
      "Epoch 39/50\n",
      "28659/28659 [==============================] - 6s 213us/step - loss: 0.1570 - acc: 0.9393 - val_loss: 0.1828 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.93334\n",
      "Epoch 40/50\n",
      "28659/28659 [==============================] - 6s 213us/step - loss: 0.1541 - acc: 0.9403 - val_loss: 0.1754 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.93334 to 0.93674, saving model to weights-improvement-40-0.94.hdf5\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28659/28659 [==============================] - 6s 192us/step - loss: 0.1535 - acc: 0.9409 - val_loss: 0.1743 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.93674\n",
      "Epoch 42/50\n",
      "28659/28659 [==============================] - 5s 191us/step - loss: 0.1510 - acc: 0.9420 - val_loss: 0.1934 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.93674\n",
      "Epoch 43/50\n",
      "28659/28659 [==============================] - 6s 200us/step - loss: 0.1511 - acc: 0.9402 - val_loss: 0.1721 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.93674 to 0.93688, saving model to weights-improvement-43-0.94.hdf5\n",
      "Epoch 44/50\n",
      "28659/28659 [==============================] - 6s 205us/step - loss: 0.1494 - acc: 0.9426 - val_loss: 0.1778 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.93688\n",
      "Epoch 45/50\n",
      "28659/28659 [==============================] - 6s 204us/step - loss: 0.1490 - acc: 0.9439 - val_loss: 0.1712 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.93688\n",
      "Epoch 46/50\n",
      "28659/28659 [==============================] - 6s 203us/step - loss: 0.1478 - acc: 0.9427 - val_loss: 0.1741 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.93688 to 0.93703, saving model to weights-improvement-46-0.94.hdf5\n",
      "Epoch 47/50\n",
      "28659/28659 [==============================] - 6s 204us/step - loss: 0.1467 - acc: 0.9433 - val_loss: 0.1744 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.93703\n",
      "Epoch 48/50\n",
      "28659/28659 [==============================] - 6s 204us/step - loss: 0.1458 - acc: 0.9430 - val_loss: 0.2236 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.93703\n",
      "Epoch 49/50\n",
      "28659/28659 [==============================] - 6s 207us/step - loss: 0.1465 - acc: 0.9432 - val_loss: 0.1786 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.93703\n",
      "Epoch 50/50\n",
      "28659/28659 [==============================] - 6s 206us/step - loss: 0.1443 - acc: 0.9445 - val_loss: 0.1875 - val_acc: 0.9281\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.93703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f436b1c7ba8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data = (X_test,y_test),epochs = 50,verbose=1,batch_size=20,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_pines = io.loadmat('Indian_pines.mat')['indian_pines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 145, 220)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_pines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels_pines = io.loadmat('Indian_pines_gt.mat')['indian_pines_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1265"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_labels_pines[gt_labels_pines == 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
